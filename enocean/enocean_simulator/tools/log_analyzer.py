# File: tools/log_analyzer.py
"""
Log Analyzer Tool for EnOcean Simulator
Analyzes the logs generated by the enhanced gateway receiver
"""

import json
import csv
import os
import sys
from datetime import datetime
from collections import defaultdict, Counter
import argparse


class LogAnalyzer:
    """Analyze EnOcean simulator logs"""

    def __init__(self, log_dir='logs'):
        self.log_dir = log_dir
        self.latest_session = None
        self.find_latest_session()

    def find_latest_session(self):
        """Find the most recent log session"""
        try:
            if not os.path.exists(self.log_dir):
                print(f"Log directory {self.log_dir} not found")
                return

            # Find all CSV files (they represent sessions)
            csv_files = [f for f in os.listdir(self.log_dir) if f.startswith('device_data_') and f.endswith('.csv')]

            if not csv_files:
                print("No log sessions found")
                return

            # Get the most recent one
            csv_files.sort()
            latest_csv = csv_files[-1]

            # Extract timestamp from filename
            timestamp = latest_csv.replace('device_data_', '').replace('.csv', '')
            self.latest_session = timestamp

            print(f"Found latest session: {timestamp}")

        except Exception as e:
            print(f"Error finding latest session: {e}")

    def get_file_paths(self, session=None):
        """Get file paths for a session"""
        if session is None:
            session = self.latest_session

        if session is None:
            print("No session specified and no latest session found")
            return None

        return {
            'csv': os.path.join(self.log_dir, f'device_data_{session}.csv'),
            'raw': os.path.join(self.log_dir, f'raw_telegrams_{session}.log'),
            'decoded': os.path.join(self.log_dir, f'decoded_data_{session}.log'),
            'stats': os.path.join(self.log_dir, f'session_stats_{session}.json'),
            'errors': os.path.join(self.log_dir, f'errors_{session}.log')
        }

    def analyze_session_stats(self, session=None):
        """Analyze session statistics"""
        files = self.get_file_paths(session)
        if not files:
            return

        try:
            with open(files['stats'], 'r') as f:
                stats = json.load(f)

            print(f"\n=== SESSION STATISTICS ===")
            print(f"Session: {session or self.latest_session}")
            print(f"Start time: {stats.get('start_time', 'Unknown')}")
            print(f"End time: {stats.get('end_time', 'Unknown')}")

            if 'session_duration_seconds' in stats:
                duration = stats['session_duration_seconds']
                minutes = int(duration // 60)
                seconds = int(duration % 60)
                print(f"Duration: {minutes}m {seconds}s")

            print(f"\nTelegram Statistics:")
            print(f"  Total telegrams: {stats.get('total_telegrams', 0)}")
            print(f"  Successful: {stats.get('successful_telegrams', 0)}")
            print(f"  Failed: {stats.get('failed_telegrams', 0)}")
            print(f"  Unknown devices: {stats.get('unknown_devices', 0)}")
            print(f"  Checksum failures: {stats.get('checksum_failures', 0)}")

            if stats.get('total_telegrams', 0) > 0:
                success_rate = (stats.get('successful_telegrams', 0) / stats['total_telegrams']) * 100
                print(f"  Success rate: {success_rate:.1f}%")

            print(f"\nDevices seen: {len(stats.get('devices_seen', []))}")
            if stats.get('devices_seen'):
                print("  Device list:")
                for device in sorted(stats['devices_seen']):
                    print(f"    - {device}")

        except Exception as e:
            print(f"Error analyzing session stats: {e}")

    # Additional helper method for better VLD telegram analysis
    @staticmethod
    def _analyze_vld_structure(data: bytes, eep_type: str) -> dict:
        """Analyze VLD telegram structure for debugging"""
        if len(data) < 2:
            return {"error": "VLD telegram too short"}

        rorg = data[0]

        # VLD structure analysis
        result = {
            "eep_type": eep_type,
            "rorg": f"0x{rorg:02X}",
            "data_length": len(data),
            "raw_data": data.hex(),
        }

        # Extract data bytes (excluding RORG, sender ID, and status)
        if len(data) >= 6:  # Minimum for VLD with sender ID
            data_bytes = data[1:-5]  # Exclude RORG and last 5 bytes (sender + status)
            result["data_bytes"] = [f"0x{b:02X}" for b in data_bytes]
            result["sender_id"] = data[-5:-1].hex()
            result["status"] = f"0x{data[-1]:02X}"

        return result
    def analyze_device_data(self, session=None, device_filter=None):
        """Analyze device data from CSV"""
        files = self.get_file_paths(session)
        if not files:
            return

        try:
            device_data = defaultdict(list)
            status_counts = Counter()
            eep_counts = Counter()

            with open(files['csv'], 'r') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    device_name = row['Device_Name']
                    if device_filter and device_filter.lower() not in device_name.lower():
                        continue

                    device_data[device_name].append(row)
                    status_counts[row['Status']] += 1
                    eep_counts[row['EEP_Type']] += 1

            print(f"\n=== DEVICE DATA ANALYSIS ===")
            print(f"Total unique devices: {len(device_data)}")
            print(f"Status distribution: {dict(status_counts)}")

            print(f"\nEEP Type distribution:")
            for eep_type, count in eep_counts.most_common():
                print(f"  {eep_type}: {count}")

            print(f"\nDevice activity:")
            for device_name, records in sorted(device_data.items()):
                successful = len([r for r in records if r['Status'] == 'SUCCESS'])
                total = len(records)
                print(f"  {device_name}: {successful}/{total} successful ({successful / total * 100:.1f}%)")

                if device_filter and device_filter.lower() in device_name.lower():
                    print(f"    Recent values:")
                    for record in records[-5:]:  # Show last 5 records
                        timestamp = record['Timestamp'][:19]  # Remove microseconds
                        decoded = record['Decoded_Data']
                        print(f"      {timestamp}: {decoded}")

        except Exception as e:
            print(f"Error analyzing device data: {e}")

    def analyze_errors(self, session=None):
        """Analyze error logs"""
        files = self.get_file_paths(session)
        if not files:
            return

        try:
            if not os.path.exists(files['errors']):
                print("No error log found")
                return

            error_types = Counter()
            recent_errors = []

            with open(files['errors'], 'r') as f:
                for line in f:
                    parts = line.strip().split(' | ')
                    if len(parts) >= 3:
                        timestamp = parts[0]
                        error_type = parts[1]
                        error_msg = parts[2]

                        error_types[error_type] += 1
                        recent_errors.append((timestamp, error_type, error_msg))

            print(f"\n=== ERROR ANALYSIS ===")
            print(f"Total errors: {sum(error_types.values())}")
            print(f"Error types:")
            for error_type, count in error_types.most_common():
                print(f"  {error_type}: {count}")

            if recent_errors:
                print(f"\nRecent errors (last 10):")
                for timestamp, error_type, error_msg in recent_errors[-10:]:
                    timestamp = timestamp[:19]  # Remove microseconds
                    print(f"  {timestamp} [{error_type}]: {error_msg[:80]}...")

        except Exception as e:
            print(f"Error analyzing errors: {e}")

    def show_raw_telegrams(self, session=None, count=10):
        """Show recent raw telegrams"""
        files = self.get_file_paths(session)
        if not files:
            return

        try:
            if not os.path.exists(files['raw']):
                print("No raw telegram log found")
                return

            print(f"\n=== RAW TELEGRAMS (last {count}) ===")

            with open(files['raw'], 'r') as f:
                lines = f.readlines()

            for line in lines[-count:]:
                parts = line.strip().split(' | ')
                if len(parts) >= 4:
                    timestamp = parts[0][:19]  # Remove microseconds
                    status = parts[1]
                    telegram = parts[2]
                    length = parts[3]
                    print(f"{timestamp} [{status}] {telegram} ({length})")

        except Exception as e:
            print(f"Error showing raw telegrams: {e}")

    def generate_report(self, session=None, output_file=None):
        """Generate comprehensive report"""
        if output_file is None:
            output_file = f"analysis_report_{session or self.latest_session}.txt"

        # Capture all output
        original_stdout = sys.stdout

        try:
            with open(output_file, 'w') as f:
                sys.stdout = f

                print(f"EnOcean Simulator Log Analysis Report")
                print(f"Generated: {datetime.now().isoformat()}")
                print("=" * 50)

                self.analyze_session_stats(session)
                self.analyze_device_data(session)
                self.analyze_errors(session)
                self.show_raw_telegrams(session, 20)

        finally:
            sys.stdout = original_stdout

        print(f"Report saved to: {output_file}")

    def list_sessions(self):
        """List all available sessions"""
        try:
            if not os.path.exists(self.log_dir):
                print(f"Log directory {self.log_dir} not found")
                return

            # Find all CSV files (they represent sessions)
            csv_files = [f for f in os.listdir(self.log_dir) if f.startswith('device_data_') and f.endswith('.csv')]

            if not csv_files:
                print("No log sessions found")
                return

            print(f"\n=== AVAILABLE SESSIONS ===")
            for csv_file in sorted(csv_files):
                timestamp = csv_file.replace('device_data_', '').replace('.csv', '')
                # Parse timestamp for readable format
                try:
                    dt = datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
                    readable = dt.strftime("%Y-%m-%d %H:%M:%S")
                    marker = " (LATEST)" if timestamp == self.latest_session else ""
                    print(f"  {timestamp} - {readable}{marker}")
                except:
                    print(f"  {timestamp}")

        except Exception as e:
            print(f"Error listing sessions: {e}")


def main():
    parser = argparse.ArgumentParser(description='Analyze EnOcean Simulator Logs')
    parser.add_argument('--log-dir', default='logs', help='Log directory path')
    parser.add_argument('--session', help='Specific session timestamp to analyze')
    parser.add_argument('--device', help='Filter analysis to specific device name')
    parser.add_argument('--report', action='store_true', help='Generate comprehensive report')
    parser.add_argument('--list', action='store_true', help='List all available sessions')
    parser.add_argument('--raw', type=int, default=0, help='Show last N raw telegrams')

    args = parser.parse_args()

    analyzer = LogAnalyzer(args.log_dir)

    if args.list:
        analyzer.list_sessions()
        return

    if args.report:
        analyzer.generate_report(args.session)
        return

    # Default analysis
    analyzer.analyze_session_stats(args.session)
    analyzer.analyze_device_data(args.session, args.device)
    analyzer.analyze_errors(args.session)

    if args.raw > 0:
        analyzer.show_raw_telegrams(args.session, args.raw)


if __name__ == "__main__":
    main()